{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2da602-b4d8-49a6-abe1-908d87077711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./local_roberta_sentiment\\\\tokenizer_config.json',\n",
       " './local_roberta_sentiment\\\\special_tokens_map.json',\n",
       " './local_roberta_sentiment\\\\vocab.json',\n",
       " './local_roberta_sentiment\\\\merges.txt',\n",
       " './local_roberta_sentiment\\\\added_tokens.json',\n",
       " './local_roberta_sentiment\\\\tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "# Download and cache the full model locally\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Optional: Save locally if you want to avoid internet next time\n",
    "model.save_pretrained(\"./local_roberta_sentiment\")\n",
    "tokenizer.save_pretrained(\"./local_roberta_sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932e843f-d825-45d1-bdc9-c0f7c0df2f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = \"./local_roberta_sentiment\"  # or the full Windows path\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path, framework=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fce8cd3-f275-4eb6-ad4e-1ac6aa755773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved reddit_sentiment_labeled.csv\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load model from local path\n",
    "model_path = \"./local_roberta_sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Create the pipeline with truncation and batch size\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    batch_size=16  # helps avoid memory errors too\n",
    ")\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"data/reddit_posts.csv\")\n",
    "df[\"full_text\"] = df[\"title\"].fillna('') + \" \" + df[\"selftext\"].fillna('')\n",
    "\n",
    "# Run prediction safely\n",
    "results = sentiment_pipeline(df[\"full_text\"].tolist())\n",
    "\n",
    "# Extract results\n",
    "df[\"label\"] = [r[\"label\"].lower() for r in results]\n",
    "\n",
    "# Save\n",
    "df.to_csv(\"reddit_sentiment_labeled.csv\", index=False)\n",
    "print(\"✅ Saved reddit_sentiment_labeled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc5c935e-6116-46c4-987b-f8fa29101fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Reddit posts\n",
    "df = pd.read_csv(\"data/reddit_posts.csv\")\n",
    "df[\"full_text\"] = df[\"title\"].fillna('') + \" \" + df[\"selftext\"].fillna('')\n",
    "\n",
    "# Truncate long texts manually\n",
    "def truncate_text(text, tokenizer, max_length=512):\n",
    "    tokens = tokenizer.encode(text, max_length=max_length, truncation=True)\n",
    "    return tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "df[\"full_text\"] = df[\"full_text\"].apply(lambda x: truncate_text(x, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78ee9ab-75ab-4694-8219-3a602c7e1462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved reddit_sentiment_labeled.csv with readable labels.\n"
     ]
    }
   ],
   "source": [
    "# Run the predictions\n",
    "results = sentiment_pipeline(df[\"full_text\"].tolist())\n",
    "\n",
    "# Map labels\n",
    "label_mapping = {\n",
    "    \"LABEL_0\": \"negative\",\n",
    "    \"LABEL_1\": \"neutral\",\n",
    "    \"LABEL_2\": \"positive\"\n",
    "}\n",
    "df[\"label\"] = [label_mapping[r[\"label\"]] for r in results]\n",
    "\n",
    "# Save results\n",
    "df.to_csv(\"reddit_sentiment_labeled.csv\", index=False)\n",
    "print(\"Saved reddit_sentiment_labeled.csv with readable labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c984a06-6cd5-420a-8c45-3b75a7eb4957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from wordcloud import WordCloud\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Load sentiment-labeled data\n",
    "df = pd.read_csv(\"reddit_sentiment_labeled.csv\")\n",
    "\n",
    "# Function to generate word cloud base64\n",
    "def generate_wordcloud_base64(text_series):\n",
    "    if text_series.empty or text_series.str.strip().str.len().sum() == 0:\n",
    "        return None\n",
    "    wordcloud = WordCloud(width=1200, height=700, background_color='white').generate(' '.join(text_series.dropna()))\n",
    "    img = BytesIO()\n",
    "    wordcloud.to_image().save(img, format='PNG')\n",
    "    return base64.b64encode(img.getvalue()).decode()\n",
    "\n",
    "# Generate word clouds\n",
    "positive_wc = generate_wordcloud_base64(df[df['label'] == 'positive'][\"full_text\"])\n",
    "neutral_wc = generate_wordcloud_base64(df[df['label'] == 'neutral'][\"full_text\"])\n",
    "negative_wc = generate_wordcloud_base64(df[df['label'] == 'negative'][\"full_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fceddba-96da-4b56-9e75-2b0e960063c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1e15da021e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = dash.Dash(__name__)\n",
    "app.title = \"Reddit Sentiment Dashboard\"\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Reddit Depression Post Sentiment Dashboard\", style={'textAlign': 'center'}),\n",
    "\n",
    "    # Sentiment Distribution Bar Chart\n",
    "    dcc.Graph(\n",
    "        id='sentiment-distribution',\n",
    "        figure={\n",
    "            'data': [go.Bar(\n",
    "                x=df['label'].value_counts().index,\n",
    "                y=df['label'].value_counts().values,\n",
    "                marker=dict(color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "            )],\n",
    "            'layout': go.Layout(title=\"Sentiment Distribution\", xaxis={'title': 'Sentiment'}, yaxis={'title': 'Count'})\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    # Polarity Histogram (optional, if polarity column exists)\n",
    "    dcc.Graph(\n",
    "        id='polarity-distribution',\n",
    "        figure={\n",
    "            'data': [go.Histogram(\n",
    "                x=df.get('polarity', pd.Series(dtype=float)),\n",
    "                nbinsx=20,\n",
    "                marker=dict(color='skyblue'),\n",
    "                opacity=0.75\n",
    "            )],\n",
    "            'layout': go.Layout(title=\"Polarity Distribution\", xaxis={'title': 'Polarity'}, yaxis={'title': 'Frequency'})\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    # Wordclouds\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.H3(\"Wordcloud - Positive\", style={'textAlign': 'center'}),\n",
    "            html.Img(src=f'data:image/png;base64,{positive_wc}', style={'width': '100%', 'height': '500px'}) if positive_wc else html.P(\"No positive text found.\")\n",
    "        ], style={'width': '32%', 'display': 'inline-block'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.H3(\"Wordcloud - Neutral\", style={'textAlign': 'center'}),\n",
    "            html.Img(src=f'data:image/png;base64,{neutral_wc}', style={'width': '100%', 'height': '500px'}) if neutral_wc else html.P(\"No neutral text found.\")\n",
    "        ], style={'width': '32%', 'display': 'inline-block'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.H3(\"Wordcloud - Negative\", style={'textAlign': 'center'}),\n",
    "            html.Img(src=f'data:image/png;base64,{negative_wc}', style={'width': '100%', 'height': '500px'}) if negative_wc else html.P(\"No negative text found.\")\n",
    "        ], style={'width': '32%', 'display': 'inline-block'}),\n",
    "    ], style={'display': 'flex', 'justify-content': 'space-around', 'padding': '30px'})\n",
    "])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2cfba4-ef16-4f47-89fd-f268427d050b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
